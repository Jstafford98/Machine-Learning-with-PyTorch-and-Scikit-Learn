{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = {'a':[1.0,5.0,10.0],'b':[2.0,6.0,11.0],'c':[3.0,np.NaN,12.0],'d':[4.0,8.0,np.NaN]}\n",
    "df = pd.DataFrame(csv_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0) # Drops rows with at least one NaN\n",
    "df.dropna(axis=1) # Drops columns with at least one NaN\n",
    "df.dropna(how='all') # -< Drop rows where all are nan\n",
    "df.dropna(thresh=4) # <- Drops rows that have fewer than 4 real values\n",
    "df.dropna(subset=['c']) # <- Drops rows where NaN appears in a specific column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "''' Data Imputation by inserting the mean value for each column '''\n",
    "imr = SimpleImputer(missing_values=np.NaN,strategy='mean')\n",
    "imr = imr.fit(df.values)\n",
    "imputed_data = imr.transform(df.values)\n",
    "\n",
    "imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Orrrrrr we can just do  '''\n",
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        ['green','M',10.1,'class2'],\n",
    "        ['red','L',13.5,'class1'],\n",
    "        ['blue','XL',15.3,'class2']\n",
    "    ],\n",
    "    columns=['color','size','price','classlabel']\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Ordinal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_mapping = {k:v for k,v in zip(['XL','L','M'],range(3,0,-1))}\n",
    "inv_size_mapping = {v:k for k,v in size_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['size'] = df['size'].map(size_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['size'].map(inv_size_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {v:k for k,v in enumerate(df.classlabel.unique())}\n",
    "inv_class_mapping = {v:k for k,v in class_mapping.items()}\n",
    "class_mapping\n",
    "inv_class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class_le = LabelEncoder()\n",
    "y = class_le.fit_transform(df.classlabel.values)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_le.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "An issue that can arise when encoding nominal data is that classifiers might mistake you encoded values for one's of an ordinal nature. For example,\\\n",
    "if you have the labels Blue,Green,Red and encode them as 1,2,3, the classifier would interpret Blue as less than Green and Red as greater than Green.\\\n",
    "Unless this is what you want, a solution to this is one hot encoding, where a dummy boolean is set as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = df[['color','size','price']].values\n",
    "color_ohe = OneHotEncoder()\n",
    "color_ohe.fit_transform(X[:,0].reshape(-1,1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "c_transf = ColumnTransformer(\n",
    "    [\n",
    "        ('onehot',OneHotEncoder(),[0]),\n",
    "        ('nothing','passthrough',[1,2])\n",
    "    ]\n",
    ")\n",
    "c_transf.fit_transform(X).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df[['color','size','price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can use get_dummies this way to one-hot encode all string columns and also reduce correlation among variables\n",
    "#This is useful, especially in classifiers that use matrix inversion which can lead to unstable estimates\n",
    "pd.get_dummies(df[['color','size','price']],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The same can be achieved using the OneHotEncoder as such \n",
    "color_ohe = OneHotEncoder(categories='auto',drop='first')\n",
    "\n",
    "c_transf = ColumnTransformer(\n",
    "    [\n",
    "        ('onehot',color_ohe,[0]),\n",
    "        ('nothing','passthrough',[1,2])\n",
    "    ]\n",
    ")\n",
    "c_transf.fit_transform(X).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test/Train Dataset Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "wine_cols = ['Class label','Alcohol','Malic Acid','Ash','Alcalinity of ash',\n",
    "             'Magnesium','Total phenols','Flavanoids','Nonflavanoid phenols',\n",
    "             'Proanthocyanins','Color intensity','Hue',\n",
    "             'OD280/OD315 of diluted wines','Proline'\n",
    "            ]\n",
    "df_wine = pd.read_csv(url,header=None)\n",
    "df_wine.columns = wine_cols\n",
    "df_wine.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X,y = df_wine.iloc[:,1:].values,df_wine.iloc[:,0].values\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.3,random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization using MinMax scaling, i.e putting all features into a range of 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "X_train_norm = mms.fit_transform(X_train)\n",
    "X_test_norm = mms.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization (Centering means and making all values within 1 standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meaningful Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 and L2 Regularization\n",
    "\n",
    "L1 regularization aims to create sparse feature vectors where most feature weights are 0. This is useful on highly-dimensional datasets with many irrelevant features.\n",
    "L2 regularization aims to reduce model complexity by penalizing large individual weights and decrease our model's dependency on training data and reduce overfitting (variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty='l1',solver='liblinear',multi_class='ovr')\n",
    "lr.fit(X_train_std,y_train)\n",
    "print('Training Accuracy:',lr.score(X_train_std,y_train))\n",
    "print('Test Accuracy:',lr.score(X_test_std,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_ # <- This is the three intercepts of our classes due to the one v rest multi_class option.\n",
    "              #    From left to right, the values represent the model that fits class 1 vs class 2&3, 2 vs 1&3, and 3 vs 1&2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_ # <- Returns n weight vectors for each model in lr.intercept_ that has n weights for n features in our training data (13 in this case for 13 features in the wine data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Graphing the effect of L1 regularizationas we scale the regularization parameter C\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "colors = ['blue','green','red','cyan','magenta','yellow','black','pink','lightblue','lightgreen','gray','indigo','orange']\n",
    "weights,params = [],[]\n",
    "\n",
    "for c in np.arange(-4.,6.):\n",
    "    lr = LogisticRegression(penalty='l1',C=10.**c,solver='liblinear',multi_class='ovr',random_state=0)\n",
    "    lr.fit(X_train_std,y_train)\n",
    "    weights.append(lr.coef_[1])\n",
    "    params.append(10**c)\n",
    "weights = np.array(weights)\n",
    "\n",
    "for column,color in zip(range(weights.shape[1]),colors):\n",
    "    plt.plot(params,weights[:,column],label=df_wine.columns[column+1],color=color)\n",
    "plt.axhline(0,color='black',linestyle='--',linewidth=3) \n",
    "plt.xlim([10**(-5),10**5])   \n",
    "plt.ylabel('Weight Coefficient')\n",
    "plt.xlabel('C (Inverse Regularization Strength)')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "ax.legend(loc='upper center',bbox_to_anchor=(1.38,1.03),ncol=1,fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Feature Selection Implementation\n",
    "\n",
    "Implementing Sequential Backward Selection, which aims to reduce K dimensional feature spaces into D dimensions. It achieves this by sequentially checking the the model's performance with the removal of each feature and selecting to remove the one feature that has the least impact on performance. It repeats this until the model has removed K-D features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone \n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class SBS:\n",
    "\n",
    "    def __init__(self,estimator,k_features,scoring=accuracy_score,test_size=.25,random_state=1):\n",
    "        self.scoring =  scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features =  k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=self.test_size,random_state=self.random_state)\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train,y_train,X_test,y_test,self.indices_)\n",
    "        self.scores_ = [score]\n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "\n",
    "            for p in combinations(self.indices_,r=dim - 1):\n",
    "                score = self._calc_score(X_train,y_train,X_test,y_test,p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -=1\n",
    "\n",
    "            self.scores_.append(scores[best])\n",
    "\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return X[:, self.indices_]\n",
    "\n",
    "    def _calc_score(self,X_train,y_train,X_test,y_test,indices):\n",
    "        self.estimator.fit(X_train[:,indices],y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:,indices])\n",
    "        score = self.scoring(y_test,y_pred)\n",
    "        return score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "sbs = SBS(knn,k_features=1)\n",
    "sbs.fit(X_train_std,y_train)\n",
    "k_feat = [len(k) for k in sbs.subsets_]\n",
    "\n",
    "plt.plot(k_feat,sbs.scores_,marker='o')\n",
    "plt.ylim([.7,1.02])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k3 = [*sbs.subsets_[10]]\n",
    "print(df_wine.columns[1:][k3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train_std,y_train)\n",
    "print('Training Accuracy:',knn.score(X_train_std,y_train))\n",
    "print('Test Accuracy',knn.score(X_test_std,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train_std[:,k3],y_train)\n",
    "print('Training Accuracy:',knn.score(X_train_std[:,k3],y_train))\n",
    "print('Test Accuracy',knn.score(X_test_std[:,k3],y_test))\n",
    "\n",
    "#While the reduced data set performed worse, in real world applications this model would benefit from being easier to interpret and make data collection simpler as there are fewer features\n",
    "#needed to be collected. It's all a balancing act of cost-benefit analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Feature Importance via Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feat_labels = df_wine.columns[1:]\n",
    "forest = RandomForestClassifier(n_estimators=500,random_state=1)\n",
    "forest.fit(X_train,y_train)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f+1,30,feat_labels[indices[f]],importances[indices[f]]))\n",
    "\n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train.shape[1]),importances[indices],align='center')\n",
    "plt.xticks(range(X_train.shape[1]),feat_labels[indices],rotation=90)\n",
    "plt.xlim([-1,X_train.shape[1]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo of Sklearn's SelectFromModel object, which selects features based on a threshold we define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sfm = SelectFromModel(forest,threshold=.1,prefit=True)\n",
    "X_selected = sfm.transform(X_train)\n",
    "print('Number of features that meet this threshold criterion: ',X_selected.shape[1])\n",
    "for f in range(X_selected.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f+1,30,feat_labels[indices[f]],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
