{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'\n",
    "df = pd.read_csv(url,header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.loc[:,2:].values\n",
    "y = df.loc[:,1].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.2,stratify=y,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Best Practices for Model Evaluation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining data preprocessing via Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(),PCA(n_components=2),LogisticRegression())\n",
    "pipe_lr.fit(X_train,y_train)\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "test_acc = pipe_lr.score(X_test,y_test)\n",
    "print(f'Test Accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessing Model Performance using Stratified K-Fold Cross Validation to tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=10).split(X_train,y_train)\n",
    "\n",
    "scores = []\n",
    "for k, (train,test) in enumerate(kfold):\n",
    "\n",
    "    pipe_lr.fit(X_train[train],y_train[train])\n",
    "    score = pipe_lr.score(X_train[test],y_train[test])\n",
    "    scores.append(score)\n",
    "    print(f'Fold: {k+1:02d}, ',f'Class distr: {np.bincount(y_train[test])}, ',f'Acc.: {score:.3f}')\n",
    "mean_acc = np.mean(scores)\n",
    "std_acc = np.std(scores)\n",
    "print(f'\\nCV Accuracy: {mean_acc:.3f} +/- {std_acc:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(estimator=pipe_lr,X=X_train,y=y_train,cv=10,n_jobs=1)\n",
    "print(f'CV Accuracy scores: {scores}')\n",
    "mean_acc = np.mean(scores)\n",
    "std_acc = np.std(scores)\n",
    "print(f'\\nCV Accuracy: {mean_acc:.3f} +/- {std_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Algos with Learning and Validation Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(),LogisticRegression(penalty='l2',max_iter=10000))\n",
    "\n",
    "train_sizes,train_scores,test_scores = learning_curve(\n",
    "    estimator=pipe_lr,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    train_sizes=np.linspace(.1,1.0,10),\n",
    "    cv=10,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores,axis=1)\n",
    "train_std = np.std(train_scores,axis=1)\n",
    "\n",
    "test_mean = np.mean(test_scores,axis=1)\n",
    "test_std = np.mean(test_scores,axis=1)\n",
    "\n",
    "plt.plot(\n",
    "    train_sizes,train_mean,\n",
    "    color='blue',marker='o',\n",
    "    markersize=5,label='Training Accuracy'\n",
    ")\n",
    "plt.fill_between(train_sizes,train_mean+train_std,train_mean-train_std,alpha=.15,color='blue')\n",
    "\n",
    "plt.plot(\n",
    "    train_sizes,test_mean,\n",
    "    color='green',linestyle='--',\n",
    "    marker='s',markersize=5,\n",
    "    label='Validation Accuracy'\n",
    ")\n",
    "plt.fill_between(train_sizes,test_mean+test_std,test_mean-test_std,alpha=.15,color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Number of Training Exmaples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8,1.03])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "param_range = [.001,.01,.1,1.0,10.0,100.0]\n",
    "train_scores,test_scores = validation_curve(\n",
    "    estimator=pipe_lr,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    param_name='logisticregression__C',\n",
    "    param_range=param_range,\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores,axis=1)\n",
    "train_std = np.std(train_scores,axis=1)\n",
    "\n",
    "test_mean = np.mean(test_scores,axis=1)\n",
    "test_std = np.std(test_scores,axis=1)\n",
    "\n",
    "plt.plot(\n",
    "    param_range,train_mean,\n",
    "    color='blue',marker='o',\n",
    "    markersize=5,label='Training Accuracy'\n",
    ")\n",
    "plt.fill_between(param_range,train_mean+train_std,train_mean-train_std,alpha=.15,color='blue')\n",
    "\n",
    "plt.plot(\n",
    "    param_range,test_mean,\n",
    "    color='green',linestyle='--',\n",
    "    marker='s',markersize=5,\n",
    "    label='Validation Accuracy'\n",
    ")\n",
    "plt.fill_between(param_range,test_mean+test_std,test_mean-test_std,alpha=.15,color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Paramter C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([.8,1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning our Model via Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe_svc = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(random_state=1)\n",
    ")\n",
    "\n",
    "param_range = [.0001,.001,.01,.1,1.0,10.,100.,1000.]\n",
    "param_grid = [\n",
    "    {\n",
    "        'svc__C':param_range,\n",
    "        'svc__kernel':['linear']\n",
    "    },\n",
    "    {\n",
    "        'svc__C':param_range,\n",
    "        'svc__gamma':param_range,\n",
    "        'svc__kernel':['rbf']\n",
    "    }\n",
    "]\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipe_svc,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=10,\n",
    "    refit=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs = gs.fit(X_train,y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = gs.best_estimator_\n",
    "clf.fit(X_train,y_train)\n",
    "print(f'Test Accuracy: {clf.score(X_test,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning Models via Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "param_range = [.0001,.001,.01,.1,1.,10.,100.,1000.]\n",
    "\n",
    "param_range = scipy.stats.loguniform(.0001,1000.)\n",
    "np.random.seed(1)\n",
    "\n",
    "param_range.rvs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "pipe_svc = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(random_state=1)\n",
    ")\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'svc__C':param_range,\n",
    "        'svc__kernel':['linear'],\n",
    "    },\n",
    "    {\n",
    "        'svc__C':param_range,\n",
    "        'svc__gamma':param_range,\n",
    "        'svc__kernel':['rbf']\n",
    "    }\n",
    "]\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=pipe_svc,\n",
    "    param_distributions=param_grid,\n",
    "    scoring='accuracy',\n",
    "    refit=True,\n",
    "    n_iter=20,\n",
    "    cv=10,\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rs = rs.fit(X_train,y_train)\n",
    "print(rs.best_score_)\n",
    "print(rs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning Models via Successive Halfing (Book example not working, try to figure this out later on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "\n",
    "hs = HalvingRandomSearchCV(\n",
    "    pipe_svc,\n",
    "    param_distributions=param_grid[1],\n",
    "    n_candidates='exhaust',\n",
    "    resource='n_samples',\n",
    "    factor=1.5,\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "hs = hs.fit(X_train,y_train)\n",
    "print(hs.best_score_)\n",
    "print(hs.best_params_)\n",
    "clf = hs.best_estimator_\n",
    "print(f'Test Accuracy: {hs.score(X_test,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Selection via Nested Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = [.0001,.001,.01,.1,1.,10.,100.,1000.]\n",
    "param_grid = [\n",
    "    {\n",
    "        'svc__C':param_range,\n",
    "        'svc__kernel':['linear'],\n",
    "    },\n",
    "    {\n",
    "        'svc__C':param_range,\n",
    "        'svc__gamma':param_range,\n",
    "        'svc__kernel':['rbf']\n",
    "    }\n",
    "]\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipe_svc,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=2\n",
    ")\n",
    "scores = cross_val_score(\n",
    "    gs, X_train, y_train,\n",
    "    scoring='accuracy',cv=5\n",
    ")\n",
    "print(f'CV Accuracy: {np.mean(scores):.3f} +/- {np.std(scores):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "gs = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=0),\n",
    "    param_grid=[\n",
    "        {'max_depth':[1,2,3,4,5,6,7,None]}\n",
    "    ],\n",
    "    scoring='accuracy',\n",
    "    cv=2\n",
    ")\n",
    "scores = cross_val_score(\n",
    "    gs,X_train,y_train,\n",
    "    scoring='accuracy',cv=5\n",
    ")\n",
    "print(f'CV Accuracy: {np.mean(scores):.3f} +/- {np.std(scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Validation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pipe_svc.fit(X_train,y_train)\n",
    "y_pred = pipe_svc.predict(X_test)\n",
    "confmat = confusion_matrix(y_true=y_test,y_pred=y_pred)\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(2.5,2.5))\n",
    "ax.matshow(confmat,cmap=plt.cm.Blues,alpha=.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j,y=i,s=confmat[i,j],va='center',ha='center')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score,  matthews_corrcoef\n",
    "\n",
    "pre_val = precision_score(y_true=y_test,y_pred=y_pred)\n",
    "print(f'Precision: {pre_val:.3f}')\n",
    "\n",
    "rec_val = recall_score(y_true=y_test,y_pred=y_pred)\n",
    "print(f'Recall: {rec_val:.3f}')\n",
    "\n",
    "f1_val = f1_score(y_true=y_test,y_pred=y_pred)\n",
    "print(f'F1: {f1_val:.3f}')\n",
    "\n",
    "mcc_val = matthews_corrcoef(y_true=y_test,y_pred=y_pred)\n",
    "print(f'MCC: {mcc_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Scoring Solution to change the label we base our scoring off of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "c_gamma_range = [.01,.1,1.,10.]\n",
    "param_grid = [\n",
    "    {\n",
    "        'svc__C':c_gamma_range,\n",
    "        'svc__kernel':['linear']\n",
    "    },\n",
    "    {\n",
    "        'svc__C':c_gamma_range,\n",
    "        'svc__gamma':c_gamma_range,\n",
    "        'svc__kernel':['rbf']\n",
    "    }\n",
    "]\n",
    "scorer = make_scorer(f1_score,pos_label=0)\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipe_svc,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "gs = gs.fit(X_train,y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reciever Operating Characteristic (ROC) and ROC Area Under Curve (ROC AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc\n",
    "from numpy import interp\n",
    "\n",
    "pipe_lr = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PCA(n_components=2),\n",
    "    LogisticRegression(\n",
    "        penalty='l2',\n",
    "        random_state=1,\n",
    "        solver='lbfgs',\n",
    "        C=100.\n",
    "    )\n",
    ")\n",
    "\n",
    "X_train2 = X_train[:,[4,14]]\n",
    "cv = list(StratifiedKFold(n_splits=3).split(X_train,y_train))\n",
    "\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "mean_tpr = 0.\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "all_tpr = []\n",
    "\n",
    "for i, (train,test) in enumerate(cv):\n",
    "    probas = pipe_lr.fit(\n",
    "        X_train2[train],\n",
    "        y_train[train]\n",
    "    ).predict_proba(X_train2[test])\n",
    "\n",
    "    fpr,tpr,threshold = roc_curve(\n",
    "        y_train[test],\n",
    "        probas[:,1],\n",
    "        pos_label=1\n",
    "    )\n",
    "\n",
    "    mean_tpr+=interp(mean_fpr,fpr,tpr)\n",
    "    mean_tpr[0] = 0.\n",
    "    roc_auc =auc(fpr,tpr)\n",
    "    plt.plot(fpr,tpr,label=f'ROC fold {i+1} (area = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot(\n",
    "    [0,1],\n",
    "    [0,1],\n",
    "    linestyle='--',\n",
    "    color=(.6,.6,.6),\n",
    "    label='Random Guessing (area=.5)',\n",
    ")\n",
    "\n",
    "mean_tpr /= len(cv)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr,mean_tpr)\n",
    "plt.plot(\n",
    "    mean_fpr,mean_tpr,'k--',label=f'Mean ROC (area={mean_auc:.2f})',\n",
    "    lw=2\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    [0,0,1],\n",
    "    [0,1,1],\n",
    "    linestyle=':',\n",
    "    color='black',\n",
    "    label='Perfect Performance (area=1.0)'\n",
    ")\n",
    "\n",
    "plt.xlim([-.05,1.05])\n",
    "plt.ylim([-.05,1.05])\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of selecting Micro average when building our scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_scorer = make_scorer(\n",
    "    score_func=precision_score,\n",
    "    pos_label=1,\n",
    "    greater_is_better=True,\n",
    "    average='micro'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imb = np.vstack((X[y==0],X[y==1][:40]))\n",
    "y_imb = np.hstack((y[y==0],y[y==1][:40]))\n",
    "\n",
    "#Prediction on imbalanced data by choosing the most prevelant data\n",
    "y_pred = np.zeros(y_imb.shape[0])\n",
    "np.mean(y_pred == y_imb) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling and Upsampling the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "X_upsampled,y_upsampled = resample(\n",
    "    X_imb[y_imb==1],\n",
    "    y_imb[y_imb==1],\n",
    "    replace=True,\n",
    "    n_samples=X_imb[y_imb==0].shape[0],\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "print(f'Number of class 1 examples before: ',X_imb[y_imb==1].shape[0])\n",
    "print(f'Number of class 1 exampels after: ',X_upsampled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bal = np.vstack((X[y==0],X_upsampled))\n",
    "y_bal = np.hstack((y[y==0],y_upsampled))\n",
    "\n",
    "#Random guessing the majority class now has lower accuracy, which means our model can actually learn useful information\n",
    "y_pred = np.zeros(y_bal.shape[0])\n",
    "np.mean(y_pred == y_bal)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
